{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I implemented three models, which are subtractor, adder-subtractor, adder-subtractor-multiplier, based on `Addition.ipynb` provided in homework3 sameple code.\n",
    "\n",
    "And I wrote three jupyter notebooks of these models, which named [Subtractor.ipynb](https://nbviewer.jupyter.org/github/rapirent/DSAI-HW3/blob/master/Subtractor.ipynb), [addition-subtractor.ipynb](https://nbviewer.jupyter.org/github/rapirent/DSAI-HW3/blob/master/addition-subtractor.ipynb) and [multiply.ipynb](https://nbviewer.jupyter.org/github/rapirent/DSAI-HW3/blob/master/multiply.ipynb). (Surely you can check out them)\n",
    "\n",
    "To leverage different configurations to compare performances of the same model, I wrote three python script of these models, which named `subtractor.py`, `addition-subtractor.py` and `multiply.py` to create figures, records, model savings. (You can use `model_load-subtractor.py`, `model_load-addition-subtractor.py` or `model_load-multiply.py` to reload models)\n",
    "\n",
    "# Idea\n",
    "\n",
    "- Based on `one-hot encording`, we can encode the symbol to the vector form.\n",
    "- If we constrained the number of the arithmetic operation on limited terms, build a NN receive this vector and do a supervised learning, it can be possible that reducing arithmetic computing problem to a `seq2seq` problem.\n",
    "    - the idea on `addition operation` was proved in howework3 sample code.\n",
    "- And I try to add symbol `-` (minus) and `*` (multiply), adjust the NN accept vector length to expand this NN to achieve more complex computing opreations.\n",
    "    - But those operations are contrained in only `two terms`.\n",
    "\n",
    "# initial \n",
    "\n",
    "- In these three jupyter notebooks, I run these models in same condition.\n",
    "    - DATA_SIZE = 60000\n",
    "    - TRAIN_SIZE = 45000\n",
    "    - DIGITS = 3\n",
    "    - RNN = layers.LSTM\n",
    "    - HIDDEN_SIZE = 128\n",
    "    - BATCH_SIZE = 128\n",
    "    - LAYERS = 1\n",
    "    - EPOCH = 100\n",
    "\n",
    "## subtractor\n",
    "\n",
    "- In subtractor, the final accuracy on test dataset whose size is 15000 is `0.9802`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./fig/subtractor-jupyter-accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - You can see even growth of accuracy of training and validating was slowing down, the accuracy of testing was still growing\n",
    "    - This can prove the model was trained well and not just due to `over-fitting` train-dataset or validate-dataset.\n",
    "    - And you can see the accuracy of testing oscillate in the beginging, but after more epoches runing , it can achieve more high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![](./fig/subtractor-jupyter-loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - the loss of training and validating is showed as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## addition-subtractor\n",
    "\n",
    "- In adder-subtracotr, the final accuracy on test dataset whose size is 15000 is `0.8534666666666667`\n",
    "\n",
    "![](./fig/addition-subtractor-jupyter-accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - the final accuracy on test dataset is NOT BAD\n",
    "    - As you seen in figure above, even growth of accuracy of training and validating was slowing down, the accuracy of testing was still growing.\n",
    "    - And it is apparently model can achieve more higher accuracy if it was trained after a few epoches, because the accuracy of testing was still oscillate.\n",
    "    \n",
    "![](./fig/addition-subtractor-jupyter-loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - According the loss of validating, the trained model may not found the (even local or global) optimum, it could be due to small dataset size and can be imporoved if there are more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiply\n",
    "\n",
    "- In adder-subtractor-multiplier, the final accuracy on test dataset whose size is 15000 is `0.5378666666666667`.\n",
    "\n",
    "![](./fig/multiply-jupyter-accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - The accuracy of validating is still low, which meant the model was NOT trained well, and may be due to very small dataset.\n",
    "    - the adder-subtractor-multiplier include three types of operations, and results of multiplication contained much larger digit numbers than addition or subtraction.\n",
    "\n",
    "![](./fig/multiply-jupyter-loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - The viewpoint of very small dataset can also be proved by the model loss figure as you can see the loss of vqlidating was increasing eventually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the experiments were done on the platform with this configuration.\n",
    "    - i9-7920X\n",
    "    - 31.1 GiB memory\n",
    "    - GTX 1080 Ti/PCIe/SSE2 * 4\n",
    "    - Ubuntu 18.04 LTS\n",
    "    \n",
    "- you can check about figures in `fig/` directory, record log in `data/` directory and corpus used in each experiments in `corpus/` directory.\n",
    "    - the prefix presents the model types: `s` for subtractor, `as` for `addition-subtractor` and `m` for `multiply` (adder-subtractor-multiplier)\n",
    "- ***the legends `test` of used figures in this section was present `validation`***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subtractor\n",
    "\n",
    "### with different epoch size in 3 digits\n",
    "\n",
    "```sh\n",
    "$ python3 ./subtractor.py \"--epoch=1\" \"--output_name=epoch1\" \"--data_size=50000\" \"--train_size=40000\" \"--digits=3\"\n",
    "$ python3 ./subtractor.py \"--epoch=2\" \"--output_name=epoch2\" \"--data_size=50000\" \"--train_size=40000\" \"--digits=3\"\n",
    "$ python3 ./subtractor.py \"--epoch=3\" \"--output_name=epoch3\" \"--data_size=50000\" \"--train_size=40000\" \"--digits=3\"\n",
    "```\n",
    "\n",
    "\n",
    "- 100 epoches:![](./fig/s-accuracy-epoch1.png)\n",
    "    - test accuracy `0.9748`\n",
    "- 200 epoches:![](./fig/s-accuracy-epoch2.png)\n",
    "    - test accuracy `0.9789`\n",
    "- 300 epoches:![](./fig/s-accuracy-epoch3.png)\n",
    "    - test accuracy `0.9786`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we seen in figures above, we can make an assumption about the epoch number, it may be better to set as `150~200`.\n",
    "- but the epoch number didn't significantly affect the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with different data size in 3 digits\n",
    "\n",
    "```sh\n",
    "python3 ./subtractor.py \"--epoch=2\" \"--output_name=train18000\" \"--data_size=38000\" \"--train_size=18000\" \"--digits=3\"\n",
    "python3 ./subtractor.py \"--epoch=2\" \"--output_name=train27000\" \"--data_size=57000\" \"--train_size=27000\" \"--digits=3\"\n",
    "python3 ./subtractor.py \"--epoch=2\" \"--output_name=train36000\" \"--data_size=66000\" \"--train_size=36000\" \"--digits=3\"\n",
    "python3 ./subtractor.py \"--epoch=2\" \"--output_name=train45000\" \"--data_size=75000\" \"--train_size=45000\" \"--digits=3\"\n",
    "python3 ./subtractor.py \"--epoch=2\" \"--output_name=train45000large\" \"--data_size=95000\" \"--train_size=45000\" \"--digits=3\"\n",
    "```\n",
    "\n",
    "- 18000 train data:![](./fig/s-accuracy-train18000.png)\n",
    "    - test accuracy `0.91135`\n",
    "- 27000 train data:![](./fig/s-accuracy-train27000.png)\n",
    "    - test accuracy `0.9600666666666666`\n",
    "- 36000 train data:![](./fig/s-accuracy-train36000.png)\n",
    "    - test accuracy `0.9765333333333334`\n",
    "- 45000 train data:![](./fig/s-accuracy-train45000.png)\n",
    "    - test accuracy `0.9863333333333333`\n",
    "- 45000 train data and larger test data (50000):![](./fig/s-accuracy-train45000large.png)\n",
    "    - test accuracy `0.9865`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- as what you can see, the substarctor of 3 digits can be well train on more than 27000 train data.\n",
    "- and it can perform well in larger test data. (0.9863333333333333 v.s. 0.9865)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with different data size in 4 digits\n",
    "\n",
    "```sh\n",
    "python3 ./subtractor.py \"--epoch=2\" \"--output_name=digit4-train45000\" \"--data_size=75000\" \"--train_size=45000\" \"--digits=4\"\n",
    "python3 ./subtractor.py \"--epoch=2\" \"--output_name=digit4-train36000\" \"--data_size=66000\" \"--train_size=36000\" \"--digits=4\"\n",
    "python3 ./subtractor.py \"--epoch=2\" \"--output_name=digit4-train60000\" \"--data_size=90000\" \"--train_size=60000\" \"--digits=4\"\n",
    "```\n",
    "\n",
    "- 36000 train data:![](./fig/s-accuracy-digit4-train36000.png)\n",
    "    - test accuracy `0.8051`\n",
    "- 45000 train data:![](./fig/s-accuracy-digit4-train45000.png)\n",
    "    - test accuracy `0.8378666666666666`\n",
    "- 60000 train data:![](./fig/s-accuracy-digit4-train60000.png)\n",
    "    - test accuracy `0.9149`\n",
    "\n",
    "- It showed that more than 45000 train dataset can perfor better training result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## addition-subtractor\n",
    "\n",
    "### with different train data size in 3 digits\n",
    "\n",
    "```sh\n",
    "python3 ./addition-subtractor.py \"--epoch=2\" \"--output_name=train18000\" \"--data_size=38000\" \"--train_size=18000\" \"--digits=3\"\n",
    "python3 ./addition-subtractor.py \"--epoch=2\" \"--output_name=train27000\" \"--data_size=57000\" \"--train_size=27000\" \"--digits=3\"\n",
    "python3 ./addition-subtractor.py \"--epoch=2\" \"--output_name=train36000\" \"--data_size=66000\" \"--train_size=36000\" \"--digits=3\"\n",
    "python3 ./addition-subtractor.py \"--epoch=2\" \"--output_name=train45000\" \"--data_size=75000\" \"--train_size=45000\" \"--digits=3\"\n",
    "python3 ./addition-subtractor.py \"--epoch=2\" \"--output_name=train60000\" \"--data_size=90000\" \"--train_size=60000\" \"--digits=3\"\n",
    "python3 ./addition-subtractor.py \"--epoch=2\" \"--output_name=train90000\" \"--data_size=120000\" \"--train_size=90000\" \"--digits=3\"\n",
    "```\n",
    "\n",
    "- 18000 train data:![](./fig/as-accuracy-train18000.png)\n",
    "    - test accuracy `0.449`\n",
    "- 27000 train data:![](./fig/as-accuracy-train27000.png)\n",
    "    - test accuracy `0.7001666666666667`\n",
    "- 36000 train data:![](./fig/as-accuracy-train36000.png)\n",
    "    - test accuracy `0.8155333333333333`\n",
    "- 45000 train data:![](./fig/as-accuracy-train45000.png)\n",
    "    - test accuracy `0.8899333333333334`\n",
    "- 60000 train data:![](./fig/as-accuracy-train60000.png)\n",
    "    - test accuracy `0.9299666666666667`\n",
    "- 90000 train data:![](./fig/as-accuracy-train90000.png)\n",
    "    - test accuracy `0.9308666666666666`\n",
    "- As what you can see, the adder-substarctor of 3 digits can be well train on more than 45000 train data.\n",
    "- After expand the train dataset size to 60000, the test accuracy growth slowed down.\n",
    "    - But can achieve high accuracy in much less epoch number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with different digit number in same train data size (75000)\n",
    "\n",
    "```sh\n",
    "python3 ./addition-subtractor.py \"--epoch=2\" \"--output_name=train45000\" \"--data_size=75000\" \"--train_size=45000\" \"--digits=3\"\n",
    "python3 ./addition-subtractor.py \"--epoch=2\" \"--output_name=digit4\" \"--data_size=75000\" \"--train_size=45000\" \"--digits=4\"\n",
    "python3 ./addition-subtractor.py \"--epoch=2\" \"--output_name=digit5\" \"--data_size=75000\" \"--train_size=45000\" \"--digits=5\"\n",
    "```\n",
    "\n",
    "- 3 digits:![](./fig/as-accuracy-train45000.png)\n",
    "    - test accuracy `0.8899333333333334`\n",
    "- 4 digits:![](./fig/as-accuracy-digit4.png)\n",
    "    - test accuracy `0.5333333333333333`\n",
    "- 5 digits:![](./fig/as-accuracy-digit5.png)\n",
    "    - test accuracy `0.191`\n",
    "- The result of this experiments proved that as long as the digit number increases, the data size should be increase too, otherwise the accuracy will decrease severely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiply (adder-subtractor-multiplier)\n",
    "\n",
    "- Because of lack of time, I just only ran one experiment in `multiply.py` and not gained a good performance.\n",
    "- But I trusted it can be improve by expanding the dataset size.\n",
    "\n",
    "### diffierent dataset size in 3 digits\n",
    "\n",
    "```sh\n",
    "python3 ./multiply.py \"--epoch=2\" \"--output_name=train18000\" \"--data_size=38000\" \"--train_size=18000\" \"--digits=3\"\n",
    "python3 ./multiply.py \"--epoch=2\" \"--output_name=train27000\" \"--data_size=57000\" \"--train_size=27000\" \"--digits=3\"\n",
    "python3 ./multiply.py \"--epoch=2\" \"--output_name=train36000\" \"--data_size=66000\" \"--train_size=36000\" \"--digits=3\"\n",
    "python3 ./multiply.py \"--epoch=2\" \"--output_name=train45000\" \"--data_size=75000\" \"--train_size=45000\" \"--digits=3\"\n",
    "python3 ./multiply.py \"--epoch=2\" \"--output_name=train60000\" \"--data_size=90000\" \"--train_size=60000\" \"--digits=3\"\n",
    "python3 ./multiply.py \"--epoch=2\" \"--output_name=train120000\" \"--data_size=120000\" \"--train_size=90000\" \"--digits=3\"\n",
    "```\n",
    "\n",
    "- 18000 train data:![](./fig/m-accuracy-train18000.png)![](./fig/m-loss-train18000.png)\n",
    "    - test accuracy `0.217`\n",
    "- 27000 train data:![](./fig/m-accuracy-train27000.png)![](./fig/m-loss-train27000.png)\n",
    "    - test accuracy `0.3271`\n",
    "- 36000 train data:![](./fig/m-accuracy-train36000.png)![](./fig/m-loss-train36000.png)\n",
    "    - test accuracy `0.4504666666666667`\n",
    "- 45000 train data:![](./fig/m-accuracy-train45000.png)![](./fig/m-loss-train45000.png)\n",
    "    - test accuracy `0.4750333333333333`\n",
    "- 60000 train data:![](./fig/m-accuracy-train60000.png)![](./fig/m-loss-train60000.png)\n",
    "    - test accuracy `0.5541666666666667`\n",
    "- 120000 train data:![](./fig/m-accuracy-train120000.png)![](./fig/m-loss-train120000.png)\n",
    "    - test accuracy `0.6574333333333333`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- According the model loss diagram, I assume the train data was not sufficient for this model becasue the loss of validating was not steady decreasing.\n",
    "- And by the observation that accuracy was increasing as long as dataset size increased, I believed it can achieve a better performance if we add more train data.\n",
    "    - Because of the digit number of result in multiplication operation was so large (if it was 3 digits, then result can be 6 digits, compared with the result is 3 digits in addition or subtraction operation).\n",
    "    - Even consider about the `multiply.py` implemented the multi-operation model, the performance on the `120000` train dataset size is acceptable (>=0.6)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My opinion about `Can we apply the same training approach for multipliction?\n",
    "\n",
    "- My answer is `yes`.\n",
    "- Refer to the experiment about multiply.py above, the accuracy can be improved by adding more train data.\n",
    "- Performance on the `120000` train dataset size is still acceptable (>=0.6).\n",
    "- Because of the digit number of result in multiplication operation was so large (if it was 3 digits, then result can be 6 digits, compared with the result is 3 digits in addition or subtraction operation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
